\section{\label{sec:intro}Introduction}

% == 1. NLG evaluation is hard, human evaluation is expensive, automatic metrics are biased
In recent years, there has been an increasing interest in tasks that require generating natural language, including
  abstractive summarization~\citep{nallapati2016abstractive},
  open-response question answering~\citep{nguyen2016ms,kovcisky2017narrativeqa}, 
  % machine translation?
  image captioning~\citep{lin2014microsoft},
  and open-domain dialogue~\citep{lowe2017ubuntu}.
Unfortunately, the evaluation of these systems remains a thorny issue because of the diversity of possible correct responses.
As the gold standard of performing human evaluation is often too expensive,
there has been a large effort developing
automatic metrics such as BLEU~\citep{papineni02bleu}, ROUGE~\citep{lin2004rouge}, METEOR~\citep{lavie2009meteor,denkowski2014meteor} and CiDER~\citep{vedantam2015cider}.
However, these have shown to be biased, correlating poorly with human metrics across different datasets and systems~\citep{liu2016evaluate,novikova2017why}.
% PL: this is fine
%\ac{I'm worried this might be too strong a statement: no one has made explicit studies about bias, just that the correlation is low.}

% == 2. Key contribution: asking question and general intuition
Can we combine automatic metrics and human evaluation to obtain
an \emph{unbiased} estimate at \emph{lower cost} than human evaluation alone?
%We should hope that such a method can rely on the model to evaluate ``easy'' cases and on humans on ``hard'' cases~\reffig{overview}.
% PL: I don't think this is the intuition, because we're not doing importance sampling
%\ac{This intuition is not really borne out by our estimator and maybe not the figure we are looking for?}
In this chapter,
we propose a simple estimator based on control variates~\citep{ripley2009stochastic},
where we average differences between human judgments and automatic metrics
rather than averaging the human judgments alone.
Provided the two are correlated,
our estimator will have lower variance and thus reduce cost.

% == 3. Contribution 2: optimality and theoretical insight.
We prove that our estimator is \emph{optimal} in the sense
that no unbiased estimator using the same automatic metric can have lower variance.
We also analyze its data efficiency (equivalently, cost savings)---the factor reduction in number of human judgments needed to obtain the same accuracy versus naive human evaluation---and show that it depends solely on
two factors:
  (a) the annotator variance (which is a function of the human evaluation prompt) and
  (b) the correlation between human judgments and the automatic metric.
This factorization allows us to calculate typical and best-case data efficiencies and accordingly refine the evaluation prompt or automatic metric.

% == 4. Contribution 3: data and empirical results.
Finally, we evaluate our estimator on state-of-the-art systems from two tasks, summarization on the CNN/Daily Mail dataset~\citep{hermann2015read,nallapati2016abstractive}
and open-response question answering on the MS MARCOv1.0 dataset~\citep{nguyen2016ms}.
To study our estimators offline,
we preemptively collected 10,000 human judgments which cover several tasks and systems.\footnote{%
An anonymized version of this data and the annotation interfaces used can be found at \url{https://bit.ly/price-of-debiasing}.}
As predicted by the theory, we find that the data efficiency depends not only on the correlation between the human and automatic metrics,
but also on the evaluation prompt.
If the automatic metric had perfect correlation, our data efficiency would be around 3, while
  if we had noiseless human judgments, our data efficiency would be about 1.5.
In reality, the reduction in cost we obtained was only about 10\%,
suggesting that improvements in both automatic metric and evaluation prompt are needed.
As one case study in improving the latter, we show that, when compared to a Likert survey, measuring the amount of post-editing needed to fix a generated sentence
reduced the annotator variance by three-fold.

