\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{berant2013freebase,fader2014open,reddy2014large}
\citation{kalyanpur2012structured}
\citation{han2015exploiting}
\citation{sparck1975report,harman1993trec}
\citation{zobel1998reliable}
\newlabel{sec:intro}{{1}{1}{Introduction}{section.1}{}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:example}{{1}{1}{An example describing entities and relations in knowledge base population.\relax }{figure.caption.1}{}}
\citation{ji2011kbp}
\citation{ellis2012kbp}
\newlabel{fig:pooling}{{2}{2}{In pooled evaluation, an evaluation dataset is constructed by labeling relation instances collected from the pooled systems (A and B) and from a team of human annotators (Humans). However, when a new system (C) is evaluated on this dataset, some of its predictions ($i_6$) are missing and can not be fairly evaluated. Here, the precision and recall for C should be $\frac {3}{3}$ and $\frac {3}{4}$ respectively, but its evaluation scores are estimated to be $\frac {2}{3}$ and $\frac {2}{3}$. The discrepancy between these two scores is called \textit {pooling bias}. \relax }{figure.caption.2}{}}
\newlabel{sec:setup}{{2}{2}{Background}{section.2}{}}
\citation{zobel1998reliable}
\citation{dang2016kbp}
\newlabel{sec:analysis}{{3}{3}{Measuring pooling bias}{section.3}{}}
\newlabel{fig:pooling-bias}{{3}{3}{Median pooling bias (difference between pooled and unpooled scores) on the top 40 systems of TAC KBP 2015 evaluation using the official and \anydoc {} scores. The bias is much smaller for the lenient \anydoc {} metric, but even so, it is larger than the largest difference between adjacent systems (1.5\% \fone {}) and typical system improvements (around 1\% \fone {}). \relax }{figure.caption.4}{}}
\citation{owen2013monte}
\newlabel{sec:method}{{4}{4}{On-demand evaluation with importance sampling}{section.4}{}}
\newlabel{sec:joint}{{4.3}{4}{Joint estimators\footnote {Proofs for claims made in this section can be found in \refapp {sampling} of the supplementary material.}}{subsection.4.3}{}}
\citation{burden1985bisection}
\newlabel{sec:application}{{5}{5}{On-demand evaluation for KBP}{section.5}{}}
\citation{webber2010measurement}
\newlabel{fig:relation-interface}{{4a}{7}{\relax }{figure.caption.10}{}}
\newlabel{sub@fig:relation-interface}{{a}{7}{\relax }{figure.caption.10}{}}
\newlabel{fig:entity-interface}{{4b}{7}{\relax }{figure.caption.10}{}}
\newlabel{sub@fig:entity-interface}{{b}{7}{\relax }{figure.caption.10}{}}
\newlabel{fig:evaluation-results}{{4f}{7}{\relax }{figure.caption.10}{}}
\newlabel{sub@fig:evaluation-results}{{f}{7}{\relax }{figure.caption.10}{}}
\newlabel{fig:simulation}{{4}{7}{\textbf {(a, b):} Interfaces for annotating relations and entities respectively. \textbf {(c, d):} A comparison of bias for the pooling, simple and joint estimators on the TAC KBP 2015 challenge. Each point in the figure is a mean of 500 repeated trials; dotted lines show the 90\% quartile. Both the simple and joint estimators are unbiased, and the joint estimator is able to significantly reduce variance. \textbf {(e):} A comparison of the number of samples used to estimate scores under the fixed and adaptive sample selection scheme. Each faint line shows the number of samples used during a single trial, while solid lines show the mean over 100 trials. The dashed line shows a square-root relationship between the number of systems evaluated and the number of samples required. Thus joint estimation combined with adaptive sample selection can reduce the number of labeled annotations required by an order of magnitude. \textbf {(f):} Precision ($P$), recall ($R$) and \fone {} scores from a pilot run of our evaluation service for ensembles of a rule-based system (R), a logistic classifier (L) and a neural network classifier (N) run on the TAC KBP 2016 document corpus. \relax }{figure.caption.10}{}}
\citation{manning2014stanford}
\citation{ratinov2011local}
\newlabel{sec:evaluation}{{6}{8}{Evaluation}{section.6}{}}
\citation{zobel1998reliable}
\citation{buckley2007bias}
\citation{webber2010measurement}
\citation{zobel1998reliable,cormack1998efficient,aslam2006statistical}
\citation{buckley2004incomplete,sakai2008information,aslam2006statistical}
\citation{aslam2006statistical}
\citation{yilmaz2008simple}
\citation{vannella2014validating,angeli2014combining,he2015question,liu2016effective}
\citation{pavlick2016gun}
\citation{angeli2014combining,adel2016comparing}
\bibstyle{emnlp_natbib}
\bibdata{refdb/all}
\bibcite{adel2016comparing}{{1}{2016}{{Adel et~al.}}{{Adel, Roth, and Sch\"{u}tze}}}
\newlabel{sec:related}{{7}{9}{Related work}{section.7}{}}
\newlabel{sec:discussion}{{8}{9}{Discussion}{section.8}{}}
\bibcite{angeli2014combining}{{2}{2014}{{Angeli et~al.}}{{Angeli, Tibshirani, Wu, and Manning}}}
\bibcite{aslam2006statistical}{{3}{2006}{{Aslam et~al.}}{{Aslam, Pavlu, and Yilmaz}}}
\bibcite{berant2013freebase}{{4}{2013}{{Berant et~al.}}{{Berant, Chou, Frostig, and Liang}}}
\bibcite{buckley2007bias}{{5}{2007}{{Buckley et~al.}}{{Buckley, Dimmick, Soboroff, and Voorhees}}}
\bibcite{buckley2004incomplete}{{6}{2004}{{Buckley and Voorhees}}{{}}}
\bibcite{burden1985bisection}{{7}{1985}{{Burden and Faires}}{{}}}
\bibcite{cormack1998efficient}{{8}{1998}{{Cormack et~al.}}{{Cormack, Palmer, and Clarke}}}
\bibcite{dang2016kbp}{{9}{2016}{{Dang}}{{}}}
\bibcite{ellis2012kbp}{{10}{2012}{{Ellis et~al.}}{{Ellis, Li, Griffitt, and Strassel}}}
\bibcite{fader2014open}{{11}{2014}{{Fader et~al.}}{{Fader, Zettlemoyer, and Etzioni}}}
\bibcite{han2015exploiting}{{12}{2015}{{Han et~al.}}{{Han, Bang, Ryu, and Lee}}}
\bibcite{harman1993trec}{{13}{1993}{{Harman}}{{}}}
\bibcite{he2015question}{{14}{2015}{{He et~al.}}{{He, Lewis, and Zettlemoyer}}}
\bibcite{ji2011kbp}{{15}{2011}{{Ji et~al.}}{{Ji, Grishman, and {Trang Dang}}}}
\bibcite{sparck1975report}{{16}{1975}{{Jones and Rijsbergen}}{{}}}
\bibcite{kalyanpur2012structured}{{17}{2012}{{Kalyanpur et~al.}}{{Kalyanpur, Boguraev, Patwardhan, Murdock, Lally, Welty, Prager, Coppola, Fokoue-Nkoutche, Zhang, Pan, and Qui}}}
\bibcite{liu2016effective}{{18}{2016}{{Liu et~al.}}{{Liu, Soderland, Bragg, Lin, Ling, and Weld}}}
\bibcite{manning2014stanford}{{19}{2014}{{Manning et~al.}}{{Manning, Surdeanu, Bauer, Finkel, Bethard, and McClosky}}}
\bibcite{owen2013monte}{{20}{2013}{{Owen}}{{}}}
\bibcite{pavlick2016gun}{{21}{2016}{{Pavlick et~al.}}{{Pavlick, Ji, Pan, and Callison-Burch}}}
\bibcite{ratinov2011local}{{22}{2011}{{Ratinov et~al.}}{{Ratinov, Roth, Downey, and Anderson}}}
\bibcite{reddy2014large}{{23}{2014}{{Reddy et~al.}}{{Reddy, Lapata, and Steedman}}}
\bibcite{sakai2008information}{{24}{2008}{{Sakai and Kando}}{{}}}
\bibcite{vannella2014validating}{{25}{2014}{{Vannella et~al.}}{{Vannella, Jurgens, Scarfini, Toscani, and Navigli}}}
\bibcite{webber2010measurement}{{26}{2010}{{Webber}}{{}}}
\bibcite{yilmaz2008simple}{{27}{2008}{{Yilmaz et~al.}}{{Yilmaz, Kanoulas, and Aslam}}}
\bibcite{zobel1998reliable}{{28}{1998}{{Zobel}}{{}}}
\newlabel{sec:implementation}{{A}{12}{Implementation details}{appendix.A}{}}
\newlabel{sec:sampling}{{B}{12}{Theoretical proofs for the sampling procedures}{appendix.B}{}}
\newlabel{thm:pih}{{1}{12}{Statistical properties of $\pih _i$}{theorem.1}{}}
\newlabel{thm:nuh}{{2}{14}{Statistical properties of $\nuh _i$}{theorem.2}{}}
\newlabel{thm:rhoh}{{3}{14}{Statistical properties of $\recallh _i$}{theorem.3}{}}
\citation{burden1985bisection}
\newlabel{sec:heuristic-wij}{{B.3}{15}{Picking heuristic $w_{ij}$}{subsection.B.3}{}}
\newlabel{sec:optimal-samples}{{B.4}{15}{Picking optimal number of samples for a new system}{subsection.B.4}{}}
\newlabel{sec:probability}{{C}{15}{Basic probability lemmas}{appendix.C}{}}
\newlabel{lem:variance-product}{{1}{15}{Mean and variance of the product of two random variables}{lemma.1}{}}
\newlabel{lem:variance-ratio}{{2}{15}{Mean and variance of the ratio of two random variables}{lemma.2}{}}
